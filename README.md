# AI Copilot - Servi√ßo de ETL e RAG Gen√©rico

[cite_start]Este projeto implementa um pipeline completo de **Retrieval-Augmented Generation (RAG)**, projetado para servir como o n√∫cleo de um copiloto de IA para qualquer sistema web complexo. [cite: 1]

[cite_start]O objetivo √© ler, processar e indexar uma base de conhecimento privada (documenta√ß√£o, c√≥digo-fonte, diagramas) e fornecer uma interface de consulta inteligente, capaz de responder perguntas complexas sobre o projeto de forma precisa e sem alucina√ß√µes, utilizando a API do Google Gemini. [cite: 1]

---

## üìã Principais Funcionalidades

* [cite_start]**Pipeline de ETL Modular:** Processa m√∫ltiplos formatos de arquivo (`.pdf`, `.docx`, `.txt`, `.md`, e arquivos de c√≥digo como `.php`, `.sql`). [cite: 1]
* [cite_start]**Base de Conhecimento Vetorial:** Utiliza `sentence-transformers` para gerar embeddings de alta qualidade e o `FAISS` para criar um √≠ndice vetorial de busca r√°pida. [cite: 1]
* [cite_start]**Acelera√ß√£o por GPU:** O processo de gera√ß√£o de embeddings e a busca s√£o acelerados utilizando a GPU via CUDA, garantindo alta performance. [cite: 1]
* [cite_start]**Persist√™ncia de Metadados:** Armazena os chunks de texto e metadados em um banco de dados **PostgreSQL** para refer√™ncia e consist√™ncia. [cite: 1]
* [cite_start]**Gera√ß√£o de Respostas com LLM:** Integra-se com a API do **Google Gemini** para sintetizar respostas coesas e precisas a partir do contexto recuperado. [cite: 1]
* [cite_start]**Ambiente Containerizado:** Todo o servi√ßo roda em **Docker** e **Docker Compose**, garantindo portabilidade e facilidade de configura√ß√£o. [cite: 1]

---

## üõ†Ô∏è Stack de Tecnologias

* [cite_start]**Linguagem:** Python 3.11 [cite: 1]
* [cite_start]**Orquestra√ß√£o:** Docker & Docker Compose [cite: 1]
* **IA & Machine Learning:**
    * [cite_start]LangChain [cite: 1]
    * [cite_start]Sentence Transformers (`all-MiniLM-L6-v2`) [cite: 1]
    * [cite_start]FAISS-GPU [cite: 1]
    * [cite_start]PyTorch [cite: 1]
    * [cite_start]Google Generative AI (Gemini 1.5 Flash) [cite: 1]
* [cite_start]**Banco de Dados:** PostgreSQL 15 [cite: 1]
* [cite_start]**Ambiente Base:** Imagem NVIDIA CUDA no Ubuntu 22.04 [cite: 1]

---

## üöÄ Configura√ß√£o do Ambiente

Siga os passos abaixo para configurar e rodar o projeto em uma nova m√°quina.

### Pr√©-requisitos

* [cite_start]Git [cite: 1]
* [cite_start]Docker Desktop [cite: 1]
* [cite_start]WSL2 (para usu√°rios Windows) [cite: 1]
* [cite_start]Drivers NVIDIA com suporte a CUDA para WSL instalados no host. [cite: 1]

### Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/elcelsius/ai_etl_project.git](https://github.com/elcelsius/ai_etl_project.git)
    cd ai_etl_project
    ```

2.  **Configure as vari√°veis de ambiente:**
    Copie o arquivo de exemplo `.env.example` para um novo arquivo chamado `.env`.
    ```bash
    cp .env.example .env
    ```
    Agora, **edite o arquivo `.env`** e preencha com suas credenciais, especialmente sua `GOOGLE_API_KEY`. O conte√∫do do `.env.example` deve ser:
    ```ini
    # Credenciais do Banco de Dados PostgreSQL
    POSTGRES_DB=ai_project
    POSTGRES_USER=postgres
    POSTGRES_PASSWORD=postgres
    POSTGRES_HOST=postgres
    POSTGRES_PORT=5432

    # Chave de API para o Google Gemini
    # Obtenha sua chave em: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
    GOOGLE_API_KEY="COLE_SUA_CHAVE_AQUI"
    ```

3.  **Popule a base de conhecimento:**
    Adicione os arquivos de documenta√ß√£o e c√≥digo-fonte do seu projeto na pasta `data/`. [cite_start]O ETL ir√° escanear todas as subpastas recursivamente. [cite: 1]

4.  **Construa a imagem Docker:**
    Este comando ir√° baixar a imagem base da NVIDIA e instalar todas as depend√™ncias. Pode demorar na primeira vez.
    ```bash
    docker-compose build
    ```

5.  **Torne os scripts execut√°veis:**
    Este passo d√° a permiss√£o necess√°ria para rodar os atalhos de treinamento e chat.
    ```bash
    chmod +x *.sh
    ```

---

## üí° Fluxo de Trabalho (Como Usar)

Com o ambiente configurado, o uso di√°rio √© simplificado pelos scripts de atalho.

### 1. Treinando a IA

Sempre que voc√™ adicionar, alterar ou remover arquivos na pasta `data/`, execute o script de treinamento para atualizar a base de conhecimento do copiloto.
```bash
./treinar_ia.sh
```

### 2. Conversando com o Copiloto
Para iniciar o chat interativo no terminal e fazer perguntas sobre seu projeto:

```Bash
./ai_etl.sh
```

Para sair do chat, digite sair ou exit.